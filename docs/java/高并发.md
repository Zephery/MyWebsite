# 高并发
QPS

高并发（High Concurrency）是互联网分布式系统架构设计中必须考虑的因素之一，它通常是指，通过设计保证**系统能够同时并行处理很多请求**。 高并发相关常用的一些指标有**响应时间**（Response Time），**吞吐量**（Throughput），**每秒查询率**QPS（Query Per Second），**并发用户数**等。

- **响应时间**：系统对请求做出响应的时间。例如系统处理一个HTTP请求需要200ms，这个200ms就是系统的响应时间。
- **吞吐量**：单位时间内处理的请求数量。
- **QPS**：每秒响应请求数。在互联网领域，这个指标和吞吐量区分的没有这么明显。
- **并发用户数**：同时承载正常使用系统功能的用户数量。例如一个即时通讯系统，同时在线量一定程度上代表了系统的并发用户数。



## 负载均衡

正所谓双拳难敌四手，高并发撑场面的首选方案就是集群化部署，一台服务器承载的QPS有限，多台服务器叠加效果就不一样了。

如何将流量转发到服务器集群，这里面就要用到负载均衡，比如：LVS 和 Nginx。

常用的负载算法有轮询法、随机法、源地址哈希法、加权轮询法、加权随机法、最小连接数法等

业务实战：对于千万级流量的秒杀业务，一台LVS扛不住流量洪峰，通常需要 10 台左右，其上面用DDNS（Dynamic DNS）做域名解析负载均衡。搭配高性能网卡，单台LVS能够提供百万以上并发能力。

注意， LVS 负责网络四层协议转发，无法按 HTTP 协议中的请求路径做负载均衡，所以还需要 Nginx

## 池化技术

复用单个连接无法承载高并发，如果每次请求都新建连接、关闭连接，考虑到TCP的三次握手、四次挥手，有时间开销浪费。池化技术的核心是资源的“预分配”和“循环使用”，常用的池化技术有线程池、进程池、对象池、内存池、连接池、协程池。

连接池的几个重要参数：最小连接数、空闲连接数、最大连接数

Linux 内核中是以进程为单元来调度资源的，线程也是轻量级进程。所以说，进程、线程都是由内核来创建并调度。协程是由应用程序创建出来的任务执行单元，比如 Go 语言中的协程“goroutine”。协程本身是运行在线程上，由应用程序自己调度，它是比线程更轻量的执行单元。

在 Go 语言中，一个协程初始内存空间是 2KB（Linux 下线程栈大小默认是 8MB），相比线程和进程来说要小很多。协程的创建和销毁完全是在用户态执行的，不涉及用户态和内核态的切换。另外，协程完全由应用程序在用户态下调用，不涉及内核态的上下文切换。协程切换时由于不需要处理线程状态，需要保存的上下文也很少，速度很快。

Go语言中协程池的实现方法有两种：抢占式和调度式。

抢占式协程池，所有任务存放到一个共享的 channel 中，多个协程同时去消费 channel 中的任务，存在锁竞争。
调度式协程池，每个协程都有自己的 channel，每个协程只消费自己的 channel。下发任务的时候，采用负载均衡算法选择合适的协程来执行任务。比如选择排队中任务最少的协程，或者简单轮询。

## 流量漏斗

上面讲的是正向方式提升系统QPS，我们也可以逆向思维，做减法，拦截非法请求，将核心能力留给正常业务！

互联网高并发流量并不都是纯净的，也有很多恶意流量（比如黑客攻击、恶意爬虫、黄牛、秒杀器等），我们需要设计流量拦截器，将那些非法的、无资格的、优先级低的流量过滤掉，减轻系统的并发压力。

拦截器分层：

网关和 WAF（Web Application Firewall，Web 应用防火墙）
采用封禁攻击者来源 IP、拒绝带有非法参数的请求、按来源 IP 限流、按用户 ID 限流等方法

风控分析。借助大数据能力分析订单等历史业务数据，对同ip多个账号下单、或者下单后支付时间过快等行为有效识别，并给账号打标记，提供给业务团队使用。
下游的每个tomcat实例应用本地内存缓存化，将一些库存存储在本地一份，做前置校验。当然，为了尽量保持数据的一致性，有定时任务，从 Redis 中定时拉取最新的库存数据，并更新到本地内存缓存中。